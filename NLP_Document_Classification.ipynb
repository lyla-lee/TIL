{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10. Document Classification ",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lyla-lee/TIL/blob/master/NLP_Document_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecOHtGBs7lDO",
        "colab_type": "text"
      },
      "source": [
        "#10장 문서 분류 (Document Classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSHRKud41Tr0",
        "colab_type": "text"
      },
      "source": [
        "#11-1 나이브 베이즈 분류(Naive Bayes Classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32FEohTU9qob",
        "colab_type": "text"
      },
      "source": [
        "##1.1 직접구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwzbT2LkrCwH",
        "colab_type": "text"
      },
      "source": [
        "### Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvX-1FJ7qXOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set = [['me free lottery', 1],\n",
        " ['free get free you', 1],\n",
        " ['you free scholarship', 0],\n",
        " ['free to contact me', 0],\n",
        " ['you won award', 0],\n",
        " ['you ticket lottery', 1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsSqpseBsFEY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a8c11164-a113-4e51-b174-31cf7e3e45de"
      },
      "source": [
        "if 'free' in training_set[1][0]:\n",
        "  print(training_set[1][0].count('free'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8irQ-xFsq39",
        "colab_type": "text"
      },
      "source": [
        "### 토큰 빈도수 및 문서별 토큰수 계산 (확률 계산을 위한 준비)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MLSe8V1sYsv",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://wikimedia.org/api/rest_v1/media/math/render/svg/98f086c560aa2f66650060277dda4f90e54e30c0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McmcTCt3nj8q",
        "colab_type": "text"
      },
      "source": [
        "### 방법 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI8-j2-waSK1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "813fa686-cc10-4066-f5b0-51e2a0a3628e"
      },
      "source": [
        "word =[]\n",
        "for i in range(len(training_set)):\n",
        "  word.append(training_set[i][0])\n",
        "  word_list = [i.split() for i in word]\n",
        "word_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['me', 'free', 'lottery'],\n",
              " ['free', 'get', 'free', 'you'],\n",
              " ['you', 'free', 'scholarship'],\n",
              " ['free', 'to', 'contact', 'me'],\n",
              " ['you', 'won', 'award'],\n",
              " ['you', 'ticket', 'lottery']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI2I9VYqd85s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "2ede1f6c-7cc3-40c3-8f72-806049838698"
      },
      "source": [
        "import numpy as np\n",
        "set_list = set([i for word in word_list for i in word])\n",
        "wordfreq1 = defaultdict(lambda : 0)\n",
        "[wordfreq1[unique_word] for unique_word in set_list]\n",
        "wordfreq2=wordfreq1.copy()\n",
        "wordfreq2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>>,\n",
              "            {'award': 0,\n",
              "             'contact': 0,\n",
              "             'free': 0,\n",
              "             'get': 0,\n",
              "             'lottery': 0,\n",
              "             'me': 0,\n",
              "             'scholarship': 0,\n",
              "             'ticket': 0,\n",
              "             'to': 0,\n",
              "             'won': 0,\n",
              "             'you': 0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVgh7PNigBQk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "83c63541-baf3-4eeb-e9cf-4ff5eac6dc19"
      },
      "source": [
        "for i in range(len(training_set)):\n",
        "  for unique_word in set_list:\n",
        "    if unique_word in training_set[i][0] and training_set[i][1]==1:\n",
        "      wordfreq1[unique_word] += training_set[i][0].count(unique_word)\n",
        "      # +=1 씩 더하면, 한문장에 free 두개일때 하나만 카운트 되니깐 수정하기\n",
        "      spam_wordfreq = wordfreq1\n",
        "\n",
        "    if unique_word in training_set[i][0] and training_set[i][1]==0:\n",
        "      wordfreq2[unique_word] +=1\n",
        "      normal_wordfreq = wordfreq2\n",
        "spam_wordfreq, normal_wordfreq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(defaultdict(<function __main__.<lambda>>,\n",
              "             {'award': 0,\n",
              "              'contact': 0,\n",
              "              'free': 3,\n",
              "              'get': 1,\n",
              "              'lottery': 2,\n",
              "              'me': 1,\n",
              "              'scholarship': 0,\n",
              "              'ticket': 1,\n",
              "              'to': 0,\n",
              "              'won': 0,\n",
              "              'you': 2}),\n",
              " defaultdict(<function __main__.<lambda>>,\n",
              "             {'award': 1,\n",
              "              'contact': 1,\n",
              "              'free': 2,\n",
              "              'get': 0,\n",
              "              'lottery': 0,\n",
              "              'me': 1,\n",
              "              'scholarship': 1,\n",
              "              'ticket': 0,\n",
              "              'to': 1,\n",
              "              'won': 1,\n",
              "              'you': 2}))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RphDK8bFnn3w",
        "colab_type": "text"
      },
      "source": [
        "### 방법 2: key값에 두개의 빈도수를 넣는 방법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4KjiGtqsbm_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "476bd837-120e-4f78-8627-56b82ab5f003"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# 범주에 속하는 토큰수 세기 1(스팸), 0(정상))\n",
        "doccnt0 = 0\n",
        "doccnt1 = 0\n",
        "\n",
        "# 토큰별로 문서내 빈도수 카운팅\n",
        "wordfreq = defaultdict(lambda : [0, 0])\n",
        "\n",
        "for doc, label in training_set:\n",
        "  words = doc.split()\n",
        "  for word in words:\n",
        "    wordfreq[word][label] += 1\n",
        "\n",
        "for key, (cnt0, cnt1) in wordfreq.items():\n",
        "  doccnt0 += cnt0\n",
        "  doccnt1 += cnt1\n",
        "\n",
        "print('doccnt0 : {}'.format(doccnt0))\n",
        "print('doccnt1 : {}'.format(doccnt1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "doccnt0 : 10\n",
            "doccnt1 : 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKs_HaKwskLP",
        "colab_type": "text"
      },
      "source": [
        "### Training : 토큰별 조건부 확률 계산 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZErdCRyrwlE0",
        "colab_type": "text"
      },
      "source": [
        "### 방법1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgCsmiCNsjjF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "b6ab34ed-5937-4f80-c5c8-919c79cf59e4"
      },
      "source": [
        "k = 0.5\n",
        "\n",
        "spam_probs = {}\n",
        "normal_probs ={}\n",
        "for (key,value) in spam_wordfreq.items():\n",
        "  spam_probs[key] = (k+ value)/ (sum(spam_wordfreq.values())+ 2*k)\n",
        "for (key,value) in normal_wordfreq.items():\n",
        "  normal_probs[key] = (k+ value)/ (sum(normal_wordfreq.values())+ 2*k)\n",
        "\n",
        "\n",
        "spam_probs, normal_probs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'award': 0.045454545454545456,\n",
              "  'contact': 0.045454545454545456,\n",
              "  'free': 0.3181818181818182,\n",
              "  'get': 0.13636363636363635,\n",
              "  'lottery': 0.22727272727272727,\n",
              "  'me': 0.13636363636363635,\n",
              "  'scholarship': 0.045454545454545456,\n",
              "  'ticket': 0.13636363636363635,\n",
              "  'to': 0.045454545454545456,\n",
              "  'won': 0.045454545454545456,\n",
              "  'you': 0.22727272727272727},\n",
              " {'award': 0.13636363636363635,\n",
              "  'contact': 0.13636363636363635,\n",
              "  'free': 0.22727272727272727,\n",
              "  'get': 0.045454545454545456,\n",
              "  'lottery': 0.045454545454545456,\n",
              "  'me': 0.13636363636363635,\n",
              "  'scholarship': 0.13636363636363635,\n",
              "  'ticket': 0.045454545454545456,\n",
              "  'to': 0.13636363636363635,\n",
              "  'won': 0.13636363636363635,\n",
              "  'you': 0.22727272727272727})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F2Y7uNDwimk",
        "colab_type": "text"
      },
      "source": [
        "### 방법 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-7oYfFowho_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 0.5\n",
        "\n",
        "wordprobs = defaultdict(lambda : [0, 0])\n",
        "for key, (cnt0, cnt1) in wordfreq.items():\n",
        "  wordprobs[key][0] = (cnt0 + k) /(2 * k + doccnt0)\n",
        "  wordprobs[key][1] = (cnt1 + k) /(2 * k + doccnt1)\n",
        "\n",
        "wordprobs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Viq9UFbs3Y2",
        "colab_type": "text"
      },
      "source": [
        "### Classify : 신규 텍스트가 주어졌을 때 확률 계산\n",
        "\n",
        ">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJgHTYT2z0ee",
        "colab_type": "text"
      },
      "source": [
        "### 방법 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypuyUtI4LAQs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "a376de52-d795-4964-dc7f-940c08c1ed1d"
      },
      "source": [
        "import math\n",
        "\n",
        "doc = \"free lottery\"\n",
        "tokens = doc.split()\n",
        "log_prob1 = log_prob0 = 0.0\n",
        "\n",
        "for word,prob0 in spam_probs.items():\n",
        "  if word in tokens:\n",
        "    log_prob0 += math.log(prob0)\n",
        "for word,prob1 in normal_probs.items():\n",
        "  if word in tokens:\n",
        "    log_prob1 += math.log(prob1)\n",
        "\n",
        "log_prob0 += math.log(sum(spam_wordfreq.values())/(sum(spam_wordfreq.values())+sum(normal_wordfreq.values())))\n",
        "log_prob1 += math.log(sum(normal_wordfreq.values())/(sum(normal_wordfreq.values())+sum(spam_wordfreq.values())))\n",
        "\n",
        "prob0 = math.exp(log_prob0)\n",
        "prob1 = math.exp(log_prob1)\n",
        "\n",
        "print(prob0)\n",
        "print(prob1)\n",
        "# print(prob1)\n",
        "print(\"스팸확률 : {}\".format( prob0 /(prob0 + prob1) * 100))\n",
        "print(\"정상확률 : {}\".format( prob1 /(prob0 + prob1) * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.03615702479338842\n",
            "0.00516528925619835\n",
            "스팸확률 : 87.49999999999999\n",
            "정상확률 : 12.500000000000009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arjvuJOBz2tT",
        "colab_type": "text"
      },
      "source": [
        "### 방법 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD_S5Xy6uP5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "doc = \"free lottery\"\n",
        "tokens = doc.split()\n",
        "\n",
        "log_prob1 = log_prob0 = 0.0\n",
        "\n",
        "for word, (prob0, prob1) in wordprobs.items():\n",
        "  if word in tokens:\n",
        "    log_prob0 += math.log(prob0) \n",
        "    log_prob1 += math.log(prob1)\n",
        "\n",
        "log_prob0 += math.log(doccnt0/(doccnt0 + doccnt1))\n",
        "log_prob1 += math.log(doccnt1/(doccnt0 + doccnt1))\n",
        "\n",
        "prob0 = math.exp(log_prob0)\n",
        "prob1 = math.exp(log_prob1)\n",
        "\n",
        "print(prob0)\n",
        "print(prob1)\n",
        "\n",
        "print(\"정상확률 : {}\".format( prob0 /(prob0 + prob1) * 100))\n",
        "print(\"스팸확률 : {}\".format( prob1 /(prob0 + prob1) * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNcqh-J90Anr",
        "colab_type": "text"
      },
      "source": [
        "# scikit learn 활용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk1KN32t0KkA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "ccfd324e-98c1-409d-8863-53573052140a"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)\n",
        "print(twenty_train.target_names)\n",
        "print(twenty_train.data[0])\n",
        "print(twenty_train.target[0])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "- IL\n",
            "   ---- brought to you by your neighborhood Lerxst ----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyzxvP0A0lwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "text_clf = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', MultinomialNB())])\n",
        "\n",
        "text_clf = text_clf.fit(twenty_train.data, twenty_train.target)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jtlYFhNIWlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MultinomialNB?"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYb3o-mVIbQR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "57cda4fd-7449-4729-e985-46eabda8d836"
      },
      "source": [
        "text_clf"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1WuqKVlIhBp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "60e09ca7-ba8b-4e3f-bee0-dfc7fe110bf3"
      },
      "source": [
        "import numpy as np\n",
        "twenty_test = fetch_20newsgroups(subset='test',  shuffle=True)\n",
        "predicted = text_clf.predict(twenty_test.data)\n",
        "np.mean(predicted == twenty_test.target)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7738980350504514"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnBcgHInIoQ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "f459b769-e08f-4ad4-b3ee-a805f6ce6513"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters_clf = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
        "                  'tfidf__use_idf': (True, False),\n",
        "                  'clf__alpha' : (1, 0.1, 0.01, 0.001, 0.0001)\n",
        "                  }\n",
        "\n",
        "gs_clf = GridSearchCV(text_clf, parameters_clf, n_jobs=-1, verbose=2)\n",
        "gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)\n",
        "print('Best score : {}'.format(gs_clf.best_score_))\n",
        "best_parameters = gs_clf.best_estimator_.get_params()\n",
        "for param_name in sorted(list(best_parameters.keys())):\n",
        "  print(\"\\t{} : {}\".format(param_name, best_parameters[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYQi2YKSIpre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted = gs_clf.best_estimator_.predict(twenty_test.data)\n",
        "np.mean(predicted == twenty_test.target)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}